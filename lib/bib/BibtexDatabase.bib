@misc{AcknowledgmentsGNUGuix,
  title = {Acknowledgments ({{GNU Guix Reference Manual}})},
  url = {https://guix.gnu.org/manual/en/html_node/Acknowledgments.html},
  urldate = {2024-09-10}
}

@misc{aleksicPodmanVsDocker2023,
  title = {Podman vs {{Docker}}: {{In-Depth Comparison}}},
  shorttitle = {Podman vs {{Docker}}},
  author = {Aleksic, Marko},
  year = {2023},
  month = dec,
  journal = {Knowledge Base by phoenixNAP},
  url = {https://phoenixnap.com/kb/podman-vs-docker},
  urldate = {2024-09-15},
  abstract = {Podman and Docker are two OCI compliant container management tools. Read this article to learn about their similarities and differences.},
  langid = {american}
}

@article{API2024,
  title = {{{API}}},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=API&oldid=1246367721},
  urldate = {2024-09-19},
  abstract = {An application programming interface (abbreviated API) is a way for two or more computer programs or components to communicate with each other. It is a type of software interface, offering a service to other pieces of software. A document or standard that describes how to build or use such a connection or interface is called an API specification. A computer system that meets this standard is said to implement or expose an API. The term API may refer either to the specification or to the implementation. Whereas a system's user interface dictates how its end-users interact with the system in question, its API dictates how to write code that takes advantage of that system's capabilities. In contrast to a user interface, which connects a computer to a person, an application programming interface connects computers or pieces of software to each other. It is not intended to be used directly by a person (the end user) other than a computer programmer who is incorporating it into the software. An API is often made up of different parts which act as tools or services that are available to the programmer. A program or a programmer that uses one of these parts is said to call that portion of the API. The calls that make up the API are also known as subroutines, methods, requests, or endpoints. An API specification defines these calls, meaning that it explains how to use or implement them. One purpose of APIs is to hide the internal details of how a system works, exposing only those parts that a programmer will find useful, and keeping them consistent even if the internal details change later. An API may be custom-built for a particular pair of systems, or it may be a shared standard allowing interoperability among many systems. There are APIs for programming languages, software libraries, computer operating systems, and computer hardware. APIs originated in the 1940s, though the term did not emerge until the 1960s and 1970s. Contemporary usage of the term API often refers to Web APIs, which allow communication between computers that are joined by the Internet. Recent developments in APIs have led to the rise in popularity of microservices, which are loosely coupled services accessed through public APIs. APIs should be versioned. There are two common versioning strategies: Additive change strategy: new features are added without modifying existing ones. Any update must be backward compatible. This strategy is suitable for small projects with low rate of change. Explicit version strategy: this strategy allows making any changes including breaking changes. This strategy is suitable for complex applications and complex changes.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1246367721}
}

@inproceedings{basetUsableDeclarativeConfiguration2017,
  title = {Usable Declarative Configuration Specification and Validation for Applications, Systems, and Cloud},
  booktitle = {Proceedings of the 18th {{ACM}}/{{IFIP}}/{{USENIX Middleware Conference}}: {{Industrial Track}}},
  author = {Baset, Salman and Suneja, Sahil and Bila, Nilton and Tuncer, Ozan and Isci, Canturk},
  year = {2017},
  month = dec,
  pages = {29--35},
  publisher = {ACM},
  address = {Las Vegas Nevada},
  doi = {10.1145/3154448.3154453},
  url = {https://dl.acm.org/doi/10.1145/3154448.3154453},
  urldate = {2024-08-23},
  abstract = {Diagnosing misconfiguration across modern software stacks is increasingly difficult. These stacks comprise multiple microservices which are deployed across a combination of containers and hosts (VMs, physical machines) in a cloud or a data center. The existing approaches for detecting misconfiguration, whether rule-based or inference, are highly specialized (e.g., security only), cumbersome to write and maintain, geared towards a host (instead of container images), and can result into false-positives or false-negatives.},
  isbn = {978-1-4503-5200-0},
  langid = {english}
}

@article{bernsteinContainersCloudLXC2014,
  title = {Containers and {{Cloud}}: {{From LXC}} to {{Docker}} to {{Kubernetes}}},
  shorttitle = {Containers and {{Cloud}}},
  author = {Bernstein, David},
  year = {2014},
  month = sep,
  journal = {IEEE Cloud Computing},
  volume = {1},
  number = {3},
  pages = {81--84},
  issn = {2325-6095},
  doi = {10.1109/MCC.2014.51},
  url = {https://ieeexplore.ieee.org/document/7036275},
  urldate = {2024-09-10},
  abstract = {This issue's "Cloud Tidbit" focuses on container technology and how it's emerging as an important part of the cloud computing infrastructure. It looks at Docker, an open source project that automates the faster deployment of Linux applications, and Kubernetes, an open source cluster manager for Docker containers.},
  keywords = {cloud,Cloud computing,containers,Containers,dockers,Google,Home appliances,Linux,Runtime,Virtual machine monitors,virtual machines}
}

@misc{BuildingImages0200,
  title = {Building Images},
  year = {12:14:28 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/get-started/docker-concepts/building-images/},
  urldate = {2024-09-15},
  abstract = {Learn how to build Docker images from a Dockerfile. You'll understand the structure of a Dockerfile, how to build an image, and how to customize the build process.},
  langid = {english}
}

@misc{BuildSystem,
  title = {Build {{System}}},
  journal = {Embedded Artistry},
  url = {https://embeddedartistry.com/fieldmanual-terms/build-system/},
  urldate = {2024-09-10},
  abstract = {A build system is a tool that provides a consistent and reusable framework for defining and automating software construction, quality enforcement, and delivery processes.},
  langid = {american}
}

@misc{burgNixprocessmgmtExperimentalNixbased2020,
  title = {Nix-Processmgmt: {{An}} Experimental {{Nix-based}} Process Manager-Agnostic Framework},
  shorttitle = {Nix-Processmgmt},
  author = {van der Burg, Sander},
  year = {2020},
  publisher = {NixCon}
}

@misc{burgSanderVanBurg2020,
  title = {Sander van Der {{Burg}}'s Blog: {{On}} Using {{Nix}} and {{Docker}} as Deployment Automation Solutions: Similarities and Differences},
  shorttitle = {Sander van Der {{Burg}}'s Blog},
  author = {Burg, Sander Van Der},
  year = {2020},
  month = jul,
  journal = {Sander van der Burg's blog},
  url = {https://sandervanderburg.blogspot.com/2020/07/on-using-nix-and-docker-as-deployment.html},
  urldate = {2024-05-28},
  keywords = {deployment,Docker,Nix,process-management}
}

@inproceedings{bzeznikNixHPCPackage2017,
  title = {Nix as {{HPC}} Package Management System},
  booktitle = {Proceedings of the {{Fourth International Workshop}} on {{HPC User Support Tools}}},
  author = {Bzeznik, Bruno and Henriot, Oliver and Reis, Valentin and Richard, Olivier and Tavard, Laure},
  year = {2017},
  month = nov,
  pages = {1--6},
  publisher = {ACM},
  address = {Denver CO USA},
  doi = {10.1145/3152493.3152556},
  url = {https://dl.acm.org/doi/10.1145/3152493.3152556},
  urldate = {2024-09-10},
  abstract = {Modern High Performance Computing systems are becoming larger and more heterogeneous. The proper management of software for the users of such systems poses a significant challenge. These users run very diverse applications that may be compiled with proprietary tools for specialized hardware. Moreover, the application life-cycle of these software may exceed the lifetime of the HPC systems themselves. These difficulties motivate the use of specialized package management systems. In this paper, we outline an approach to HPC package development, deployment, management, sharing, and reuse based on the Nix functional package manager. We report our experience with this approach inside the GRICAD HPC center[GRICAD 2017a] in Grenoble over a 12 month period and compare it to other existing approaches.},
  isbn = {978-1-4503-5130-0},
  langid = {english}
}

@misc{Cache0200,
  title = {Cache},
  year = {12:14:28 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/build/cache/},
  urldate = {2024-09-19},
  abstract = {Improve your build speed with effective use of the build cache},
  langid = {english}
}

@article{CentralProcessingUnit2024,
  title = {Central Processing Unit},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Central_processing_unit&oldid=1243367426},
  urldate = {2024-09-19},
  abstract = {A central processing unit (CPU), also called a central processor, main processor, or just processor, is the most important processor in a given computer. Its electronic circuitry executes instructions of a computer program, such as arithmetic, logic, controlling, and input/output (I/O) operations. This role contrasts with that of external components, such as main memory and I/O circuitry, and specialized coprocessors such as graphics processing units (GPUs). The form, design, and implementation of CPUs have changed over time, but their fundamental operation remains almost unchanged. Principal components of a CPU include the arithmetic--logic unit (ALU) that performs arithmetic and logic operations, processor registers that supply operands to the ALU and store the results of ALU operations, and a control unit that orchestrates the fetching (from memory), decoding and execution (of instructions) by directing the coordinated operations of the ALU, registers, and other components. Modern CPUs devote a lot of semiconductor area to caches and instruction-level parallelism to increase performance and to CPU modes to support operating systems and virtualization. Most modern CPUs are implemented on integrated circuit (IC) microprocessors, with one or more CPUs on a single IC chip. Microprocessor chips with multiple CPUs are called multi-core processors. The individual physical CPUs, called processor cores, can also be multithreaded to support CPU-level multithreading. An IC that contains a CPU may also contain memory, peripheral interfaces, and other components of a computer; such integrated devices are variously called microcontrollers or systems on a chip (SoC).},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1243367426}
}

@article{Cgroups2024,
  title = {Cgroups},
  year = {2024},
  month = may,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Cgroups&oldid=1225572362},
  urldate = {2024-09-15},
  abstract = {cgroups (abbreviated from control groups) is a Linux kernel feature that limits, accounts for, and isolates the resource usage (CPU, memory, disk I/O, etc.) of a collection of processes. Engineers at Google started the work on this feature in 2006 under the name "process containers". In late 2007, the nomenclature changed to "control groups" to avoid confusion caused by multiple meanings of the term "container" in the Linux kernel context, and the control groups functionality was merged into the Linux kernel mainline in kernel version 2.6.24, which was released in January 2008. Since then, developers have added many new features and controllers, such as support for kernfs in 2014, firewalling, and unified hierarchy. cgroup v2 was merged in Linux kernel 4.5 with significant changes to the interface and internal functionality.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1225572362}
}

@article{CICD2024,
  title = {{{CI}}/{{CD}}},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=CI/CD&oldid=1245821946},
  urldate = {2024-09-19},
  abstract = {In software engineering, CI/CD or CICD is the combined practices of continuous integration (CI) and continuous delivery (CD) or, less often, continuous deployment. They are sometimes referred to collectively as continuous development or continuous software development.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1245821946}
}

@misc{Containerd,
  title = {Containerd},
  url = {https://containerd.io/},
  urldate = {2024-09-19},
  abstract = {An industry-standard container runtime with an emphasis on simplicity, robustness, and portability},
  langid = {american}
}

@misc{ContainerImageImmutability2016,
  title = {Container {{Image Immutability}} and the {{Power}} of {{Metadata}}},
  year = {2016},
  month = nov,
  journal = {CloudBees},
  url = {https://www.cloudbees.com/blog/container-image-immutability-power-metadata},
  urldate = {2024-09-15},
  abstract = {One of the principles of Docker containers is that an image is immutable -- once built, it's unchangeable, and if you want to make changes, you'll get a new image as a result.},
  langid = {american}
}

@misc{ContainerizedApplicationRun,
  title = {Containerized Application Run Tools Worldwide 2023},
  journal = {Statista},
  url = {https://www.statista.com/statistics/1450939/containerized-application-run-tools/},
  urldate = {2024-07-07},
  abstract = {Docker compose was the main tool used in 2023 to run containerized applications during development, with 60 percent of respondents worldwide reporting the same.},
  langid = {english}
}

@misc{ContainerizingApplicationsWorldwide,
  title = {Containerizing Applications Worldwide 2021},
  journal = {Statista},
  url = {https://www.statista.com/statistics/1224519/containerizing-applications-reasons/},
  urldate = {2024-07-07},
  abstract = {According to a recent global survey, 36 percent of respondents named application portability as a key driver for containerizing applications.},
  langid = {english}
}

@misc{ContainerRuntimes,
  title = {Container {{Runtimes}}},
  journal = {Kubernetes},
  url = {https://kubernetes.io/docs/setup/production-environment/container-runtimes/},
  urldate = {2024-09-15},
  abstract = {Note: Dockershim has been removed from the Kubernetes project as of release 1.24. Read the Dockershim Removal FAQ for further details. You need to install a container runtime into each node in the cluster so that Pods can run there. This page outlines what is involved and describes related tasks for setting up nodes. Kubernetes 1.31 requires that you use a runtime that conforms with the Container Runtime Interface (CRI).},
  chapter = {docs},
  langid = {english}
}

@misc{ContainerRuntimeTechnology,
  title = {Container Runtime Technology 2022},
  journal = {Statista},
  url = {https://www.statista.com/statistics/1372411/container-runtime-technology/},
  urldate = {2024-07-07},
  abstract = {Docker is the dominant technology currently being used as a runtime engine, with about 87 percent of respondents reporting using the technology.},
  langid = {english}
}

@misc{ContainerTechnology,
  title = {Container Technology},
  journal = {Statista},
  url = {https://www.statista.com/study/80311/container-technology/},
  urldate = {2024-07-07},
  abstract = {Container technology - Get the report with graphs and tables on statista.com!},
  langid = {english}
}

@misc{ContainerUsageWorldwide,
  title = {Container Usage Worldwide 2023},
  journal = {Statista},
  url = {https://www.statista.com/statistics/1450928/container-usage/},
  urldate = {2024-07-07},
  abstract = {In 2023, 51 percent of worldwide respondents reported that they run multiple applications in containers, while 50 percent reported running single applications in single containers while using backing services.},
  langid = {english}
}

@misc{courtesFunctionalPackageManagement2013,
  title = {Functional {{Package Management}} with {{Guix}}},
  author = {Court{\`e}s, Ludovic},
  year = {2013},
  month = may,
  number = {arXiv:1305.4584},
  eprint = {1305.4584},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1305.4584},
  urldate = {2024-09-10},
  abstract = {We describe the design and implementation of GNU Guix, a purely functional package manager designed to support a complete GNU/Linux distribution. Guix supports transactional upgrades and roll-backs, unprivileged package management, per-user profiles, and garbage collection. It builds upon the low-level build and deployment layer of the Nix package manager. Guix uses Scheme as its programming interface. In particular, we devise an embedded domain-specific language (EDSL) to describe and compose packages. We demonstrate how it allows us to benefit from the host general-purpose programming language while not compromising on expressiveness. Second, we show the use of Scheme to write build programs, leading to a ``two-tier'' programming system.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Programming Languages}
}

@misc{Crio2024,
  title = {Cri-o},
  year = {2024},
  month = jul,
  url = {https://cri-o.io/},
  urldate = {2024-09-19}
}

@article{DependencyHell2024,
  title = {Dependency Hell},
  year = {2024},
  month = mar,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Dependency_hell&oldid=1214980629},
  urldate = {2024-05-31},
  abstract = {Dependency hell is a colloquial term for the frustration of some software users who have installed software packages which have dependencies on specific versions of other software packages. The dependency issue arises when several packages have dependencies on the same shared packages or libraries, but they depend on different and incompatible versions of the shared packages. If the shared package or library can only be installed in a single version, the user may need to address the problem by obtaining newer or older versions of the dependent packages. This, in turn, may break other dependencies and push the problem to another set of packages.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1214980629}
}

@misc{DevelopingContainerUsing,
  title = {Developing inside a {{Container}} Using {{Visual Studio Code Remote Development}}},
  url = {https://code.visualstudio.com/docs/devcontainers/containers},
  urldate = {2024-09-30},
  abstract = {Developing inside a Container using Visual Studio Code Remote Development},
  langid = {english}
}

@article{DevOps2024,
  title = {{{DevOps}}},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=DevOps&oldid=1245953239},
  urldate = {2024-09-19},
  abstract = {DevOps is a methodology in the software development and IT industry. Used as a set of practices and tools, DevOps integrates and automates the work of software development (Dev) and IT operations (Ops) as a means for improving and shortening the systems development life cycle. DevOps is complementary to agile software development; several DevOps aspects came from the agile way of working. Automation is an important part of DevOps. Software programmers and architects should use "fitness functions" to keep their software in check.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1245953239}
}

@misc{DockerDevelopmentBest0100,
  title = {Docker Development Best Practices},
  year = {09:37:30 +0100 +0100},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/develop/dev-best-practices/},
  urldate = {2024-05-31},
  abstract = {Rules of thumb for making your life easier as a Docker application developer},
  langid = {english}
}

@misc{DockerEngine0200,
  title = {Docker {{Engine}}},
  year = {12:14:28 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/engine/},
  urldate = {2024-09-19},
  abstract = {Find a comprehensive overview of Docker Engine, including how to install, storage details, networking, and more},
  langid = {english}
}

@misc{DockerfileReference0200,
  title = {Dockerfile Reference},
  year = {21:17:19 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/reference/dockerfile/},
  urldate = {2024-09-15},
  abstract = {Find all the available commands you can use in a Dockerfile and learn how to use them, including COPY, ARG, ENTRYPOINT, and more.},
  langid = {english}
}

@misc{DockerHomepage2022,
  title = {Docker {{Homepage}}},
  shorttitle = {Docker},
  year = {2022},
  month = may,
  url = {https://www.docker.com/},
  urldate = {2024-05-31},
  abstract = {Docker is a platform designed to help developers build, share, and run container applications. We handle the tedious setup, so you can focus on the code.},
  langid = {american}
}

@misc{DockerHubContainer,
  title = {Docker {{Hub Container Image Library}} {\textbar} {{App Containerization}}},
  url = {https://hub.docker.com},
  urldate = {2024-09-15},
  abstract = {Welcome to the world's largest container registry built for developers and open source contributors to find, use, and share their container images. Build, push and pull.},
  langid = {english}
}

@inproceedings{dolstraCharonDeclarativeProvisioning2013,
  title = {Charon: {{Declarative}} Provisioning and Deployment},
  shorttitle = {Charon},
  booktitle = {2013 1st {{International Workshop}} on {{Release Engineering}} ({{RELENG}})},
  author = {Dolstra, Eelco and Vermaas, Rob and Levy, Shea},
  year = {2013},
  month = may,
  pages = {17--20},
  doi = {10.1109/RELENG.2013.6607691},
  url = {https://ieeexplore.ieee.org/document/6607691/?arnumber=6607691},
  urldate = {2024-07-07},
  abstract = {We introduce Charon, a tool for automated provisioning and deployment of networks of machines from declarative specifications. Building upon NixOS, a Linux distribution with a purely functional configuration management model, Charon specifications completely describe the desired configuration of sets of ``logical'' machines, including all software packages and services that need to be present on those machines, as well as their desired ``physical'' characteristics. Given such specifications, Charon will provision cloud resources (such as Amazon EC2 instances) as required, build and deploy packages, and activate services. We argue why declarativity and integrated provisioning and configuration management are important properties, and describe our experience with Charon.},
  keywords = {Databases,IP networks,Linux,Production,Servers,Software,Testing}
}

@article{dolstraNixOSPurelyFunctional2008,
  title = {{{NixOS}}: A Purely Functional {{Linux}} Distribution},
  shorttitle = {{{NixOS}}},
  author = {Dolstra, Eelco and L{\"o}h, Andres},
  year = {2008},
  month = sep,
  journal = {SIGPLAN Not.},
  volume = {43},
  number = {9},
  issn = {0362-1340},
  doi = {10.1145/1411203.1411255},
  url = {https://dl.acm.org/doi/10.1145/1411203.1411255},
  urldate = {2024-09-10},
  abstract = {Existing package and system configuration management tools suffer from an imperative model, where system administration actions such as upgrading packages or changes to system configuration files are stateful: they destructively update the state of the system. This leads to many problems, such as the inability to roll back changes easily, to run multiple versions of a package side-by-side, to reproduce a configuration deterministically on another machine, or to reliably upgrade a system. In this paper we show that we can overcome these problems by moving to a purely functional system configuration model. This means that all static parts of a system (such as software packages, configuration files and system startup scripts) are built by pure functions and are immutable, stored in a way analogously to a heap in a purely function language. We have implemented this model in NixOS, a non-trivial Linux distribution that uses the Nix package manager to build the entire system configuration from a purely functional specification.}
}

@article{dolstraNixSafePolicyFree2004,
  title = {Nix: {{A Safe}} and {{Policy-Free System}} for {{Software Deployment}}},
  author = {Dolstra, Eelco and {de Jonge}, Merijn and Visser, Eelco},
  year = {2004},
  abstract = {Existing systems for software deployment are neither safe nor sufficiently flexible. Primary safety issues are the inability to enforce reliable specification of component dependencies, and the lack of support for multiple versions or variants of a component. This renders deployment operations such as upgrading or deleting components dangerous and unpredictable. A deployment system must also be flexible (i.e., policy-free) enough to support both centralised and local package management, and to allow a variety of mechanisms for transferring components. In this paper we present Nix, a deployment system that addresses these issues through a simple technique of using cryptographic hashes to compute unique paths for component instances.},
  langid = {english}
}

@misc{dolstraPurelyFunctionalSoftware2006,
  type = {Dissertation},
  title = {The Purely Functional Software Deployment Model},
  author = {Dolstra, E.},
  year = {2006},
  month = jan,
  publisher = {Utrecht University},
  url = {https://dspace.library.uu.nl/handle/1874/7540},
  urldate = {2024-09-10},
  abstract = {Software deployment is the set of activities related to getting  software components to work on the machines of end users.  It includes  activities such as installation, upgrading, uninstallation, and so on.  Many tools have been developed to support deployment, but they all  have serious limitations with respect to correctness.  For instance,  the installation of a component can lead to the failure of previously  installed components; a component might require other components that  are not present; and it is generally difficult to undo deployment  actions.  The fundamental causes of these problems are a lack of  isolation between components, the difficulty in identifying the  dependencies between components, and incompatibilities between  versions and variants of components.      This thesis describes a better approach based on a purely functional  deployment model, implemented in a deployment system called Nix.  Components are stored in isolation from each other in a Nix store.  Each component has a name that contains a cryptographic hash of all  inputs that contributed to its build process, and the content of a  component never changes after it has been built.  Hence the model is  purely functional.      This storage scheme provides several important advantages.  First, it  ensures isolation between components: if two components differ in any  way, they will be stored in different locations and will not overwrite  each other.  Second, it allows us to identify component dependencies.  Undeclared build time dependencies are prevented due to the absence of  "global" component directories used in other deployment systems.  Runtime dependencies can be found by scanning for cryptographic hashes  in the binary contents of components, a technique analogous to  conservative garbage collection in programming language  implementation.  Since dependency information is complete, complete  deployment can be performed by copying closures of components under  the dependency relation.      Developers and users are not confronted with components' cryptographic  hashes directly.  Components are built automatically from Nix  expressions, which describe how to build and compose arbitrary  software components; hashes are computed as part of this process.  Components are automatically made available to users through "user  environments", which are synthesised sets of activated components.  User environments enable atomic upgrades and rollbacks, as well as  different sets of activated components for different users.      Nix expressions provide a source-based deployment model.  However,  source-based deployment can be transparently optimised into binary  deployment by making pre-built binaries (keyed on their cryptographic  hashes) available in a shared location such as a network server.  This  is referred to as transparent source/binary deployment.      The purely functional deployment model has been validated by applying  it to the deployment of more than 278 existing Unix packages.  In  addition, this thesis shows that the model can be applied naturally to  the related activities of continuous integration using build farms,  service deployment and build management.},
  copyright = {Open Access (free)},
  isbn = {9789039341308},
  langid = {english},
  annotation = {Accepted: 2006-01-18T13:03:05Z}
}

@misc{emmanuelNixSpaceOdyssey2022,
  title = {Nix: A Space Odyssey},
  shorttitle = {Nix},
  author = {Emmanuel, Leandro and Kiperman, Reina},
  year = {2022},
  publisher = {NixCon}
}

@misc{GitHubNixOSNixa,
  title = {{{GitHub}} - {{NixOS}}/Nix: {{Nix}}, the Purely Functional Package Manager},
  url = {https://github.com/NixOS/nix},
  urldate = {2024-05-31}
}

@article{GNU2024,
  title = {{{GNU}}},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=GNU&oldid=1246274098},
  urldate = {2024-09-19},
  abstract = {GNU ( ) is an extensive collection of free software (394 packages as of June 2024), which can be used as an operating system or can be used in parts with other operating systems. The use of the completed GNU tools led to the family of operating systems popularly known as Linux. Most of GNU is licensed under the GNU Project's own General Public License (GPL). GNU is also the project within which the free software concept originated. Richard Stallman, the founder of the project, views GNU as a "technical means to a social end". Relatedly, Lawrence Lessig states in his introduction to the second edition of Stallman's book Free Software, Free Society that in it Stallman has written about "the social aspects of software and how Free Software can create community and social justice".},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1246274098}
}

@misc{GNUGuixTransactional,
  title = {{{GNU Guix}} Transactional Package Manager and Distribution --- {{GNU~Guix}}},
  url = {https://guix.gnu.org/},
  urldate = {2024-09-10}
}

@inproceedings{gomezImpactFunctionalPackage2020,
  title = {Impact of {{Functional Package Manager Over}} a {{Non-Traditional High Performance Computing System}}},
  booktitle = {2020 {{IEEE Colombian Conference}} on {{Communications}} and {{Computing}} ({{COLCOM}})},
  author = {Gomez, Carlos Eduardo and Barrios H., Carlos J. and Richard, Olivier},
  year = {2020},
  month = aug,
  publisher = {IEEE},
  address = {Cali, Colombia},
  doi = {10.1109/COLCOM50121.2020.9219768},
  url = {https://ieeexplore.ieee.org/document/9219768/},
  urldate = {2024-05-31},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-72818-715-0}
}

@inproceedings{goswamiReproducibleHighPerformance2022,
  title = {Reproducible {{High Performance Computing}} without {{Redundancy}} with {{Nix}}},
  booktitle = {2022 {{Seventh International Conference}} on {{Parallel}}, {{Distributed}} and {{Grid Computing}} ({{PDGC}})},
  author = {Goswami, Rohit and S., Ruhila and Goswami, Amrita and Goswami, Sonaly and Goswami, Debabrata},
  year = {2022},
  month = nov,
  pages = {238--242},
  issn = {2573-3079},
  doi = {10.1109/PDGC56933.2022.10053342},
  url = {https://ieeexplore.ieee.org/document/10053342/?arnumber=10053342},
  urldate = {2024-07-07},
  abstract = {High performance computing (HPC) clusters are typically managed in a restrictive manner; the large user base makes cluster administrators unwilling to allow privilege escalation. Here we discuss existing methods of package management, including those which have been developed with scalability in mind, and enumerate the drawbacks and advantages of each management methodology. We contrast the paradigms of containerization via docker, virtualization via KVM, pod-infrastructures via Kubernetes, and specialized HPC packaging systems via Spack and identify key areas of neglect. We demonstrate how functional programming due to reliance on immutable states has been leveraged for deterministic package management via the nix-language expressions. We show its associated ecosystem is a prime candidate for HPC package management. We further develop guidelines and identify bottlenecks in the existing structure and present the methodology by which the nix ecosystem should be developed further as an optimal tool for HPC package management. We assert that the caveats of the nix ecosystem can easily mitigated by considerations relevant only to HPC systems, without compromising on functional methodology and features of the nix-language. We show that benefits of adoption in terms of generating reproducible derivations in a secure manner allow for workflows to be scaled across heterogeneous clusters. In particular, from the implementation hurdles faced during the compilation and running of the d-SEAMS scientific software engine, distributed as a nix-derivation on an HPC cluster, we identify communication protocols for working with SLURM and TORQUE user resource allocation queues. These protocols are heuristically defined and described in terms of the reference implementation required for queue-efficient nix builds.},
  keywords = {Ecosystems,functional-derivations,functional-package-management,High performance computing,high-performance-computing,nix-lang,Packaging,Protocols,reproducible-research,Resource management,Software,Torque}
}

@inproceedings{guilloteauPainlessTranspositionReproducible2022,
  title = {Painless {{Transposition}} of {{Reproducible Distributed Environments}} with {{NixOS Compose}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Cluster Computing}} ({{CLUSTER}})},
  author = {Guilloteau, Quentin and Bleuzen, Jonathan and Poquet, Millian and Richard, Olivier},
  year = {2022},
  month = sep,
  pages = {1--12},
  issn = {2168-9253},
  doi = {10.1109/CLUSTER51413.2022.00051},
  url = {https://ieeexplore.ieee.org/document/9912715/?arnumber=9912715},
  urldate = {2024-07-07},
  abstract = {Development of environments for distributed systems is a tedious and time-consuming iterative process. The reproducibility of such environments is a crucial factor for rigorous scientific contributions. We think that being able to smoothly test environments both locally and on a target dis-tributed platform makes development cycles faster and reduces the friction to adopt better experimental practices. To address this issue, this paper introduces the notion of environment transposition and implements it in NixOS Compose, a tool that generates reproducible distributed environments. It enables users to deploy their environments on virtualized (docker, QEMU) or physical (Grid'5000) platforms with the same unique description of the environment. We show that NixOS Compose enables to build reproducible environments without overhead by comparing it to state-of-the-art solutions for the generation of distributed environments (EnOSlib and Kameleon). NixOS Compose actually enables substantial performance improvements on image building time over Kameleon (up to 11x faster for initial builds and up to 19x faster when building a variation of an existing environment).},
  keywords = {Buildings,Cluster computing,Deployment,Distributed Systems,Friction,Iterative methods,Nix,Reproducibility,Reproducibility of results,System Image}
}

@inproceedings{hegdePackageManagementSystem2021,
  title = {Package {{Management System}} in {{Linux}}},
  booktitle = {2021 {{Asian Conference}} on {{Innovation}} in {{Technology}} ({{ASIANCON}})},
  author = {Hegde, Shrinidhi G and Ranjani, G},
  year = {2021},
  month = aug,
  pages = {1--6},
  doi = {10.1109/ASIANCON51346.2021.9544805},
  url = {https://ieeexplore.ieee.org/document/9544805/?arnumber=9544805},
  urldate = {2024-09-10},
  abstract = {In the Linux environment, there are two common methods for delivering software: source code and pre-compiled binaries. Open-source software can benefit from source-code availability. Close-source software, on the other hand, requires a pre-compiled binary. Unlike Windows, Linux distributions such as Ubuntu, Red Hat, CentOS, and Debian come in a variety of flavours. Various Linux distributions necessitate the use of distinct binary installation packages. Red Hat and CentOS, for example, use. rpm packages, but Ubuntu and Debian require. deb packages. Developers must compile software on as many Linux computers as their supported Linux versions in order to create a software package appropriate for a wide range of Linux distributions. This procedure is inefficient, time-consuming, and difficult to manage. A method for creating and managing software packages is created here, that only requires one Linux machine. This system automates the export of software source code from a version control system, the editing of package configuration, the building of software packages, and the management of software versions. The packages for CPU performance libraries are built using this approach, which has been tested and utilised on a large scale. It has been found to speed up software release, usage and reduce the efforts and complexities. It's also simple to use, especially for those who aren't familiar with Linux.},
  keywords = {Codes,Computers,Control systems,Debian,Linux,Package management system,RPM,Software,Software packages,Spack,Technological innovation}
}

@inproceedings{henkelLearningUnderstandingSupporting2020,
  title = {Learning from, Understanding, and Supporting {{DevOps}} Artifacts for Docker},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE}} 42nd {{International Conference}} on {{Software Engineering}}},
  author = {Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas},
  year = {2020},
  month = jun,
  pages = {38--49},
  publisher = {ACM},
  address = {Seoul South Korea},
  doi = {10.1145/3377811.3380406},
  url = {https://dl.acm.org/doi/10.1145/3377811.3380406},
  urldate = {2024-05-31},
  isbn = {978-1-4503-7121-6},
  langid = {english}
}

@misc{hensingArionFastNixOS2019,
  title = {Arion: Fast {{NixOS}} on {{Docker Compose}}},
  shorttitle = {Arion},
  author = {Hensing, Robert},
  year = {2019},
  publisher = {NixCon}
}

@misc{hornClemenscodesWebserver2024,
  title = {Clemenscodes/Webserver},
  author = {Horn, Clemens},
  year = {2024},
  month = sep,
  url = {https://github.com/clemenscodes/webserver},
  urldate = {2024-09-19},
  abstract = {Rust webserver with Tailwind and HTMX}
}

@misc{hornClemenscodesWebserverActions2024,
  title = {Clemenscodes/Webserver/Actions},
  author = {Horn, Clemens},
  year = {2024},
  month = sep,
  url = {https://github.com/clemenscodes/webserver/actions},
  urldate = {2024-09-19},
  abstract = {GitHub Actions Workflows}
}

@article{HTML2024,
  title = {{{HTML}}},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=HTML&oldid=1246480484},
  urldate = {2024-09-19},
  abstract = {Hypertext Markup Language (HTML) is the standard markup language for documents designed to be displayed in a web browser. It defines the content and structure of web content. It is often assisted by technologies such as Cascading Style Sheets (CSS) and scripting languages such as JavaScript. Web browsers receive HTML documents from a web server or from local storage and render the documents into multimedia web pages. HTML describes the structure of a web page semantically and originally included cues for its appearance. HTML elements are the building blocks of HTML pages. With HTML constructs, images and other objects such as interactive forms may be embedded into the rendered page. HTML provides a means to create structured documents by denoting structural semantics for text such as headings, paragraphs, lists, links, quotes, and other items. HTML elements are delineated by tags, written using angle brackets. Tags such as {$<$}img{$>$} and {$<$}input{$>$} directly introduce content into the page. Other tags such as {$<$}p{$>$} and {$<$}/p{$>$} surround and provide information about document text and may include sub-element tags. Browsers do not display the HTML tags but use them to interpret the content of the page. HTML can embed programs written in a scripting language such as JavaScript, which affects the behavior and content of web pages. The inclusion of CSS defines the look and layout of content. The World Wide Web Consortium (W3C), former maintainer of the HTML and current maintainer of the CSS standards, has encouraged the use of CSS over explicit presentational HTML since 1997. A form of HTML, known as HTML5, is used to display video and audio, primarily using the {$<$}canvas{$>$} element, together with JavaScript.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1246480484}
}

@misc{HtmxHighPower,
  title = {{$<$}/{$>$} Htmx - High Power Tools for Html},
  url = {https://htmx.org/},
  urldate = {2024-09-19}
}

@article{Identifier2024,
  title = {Identifier},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Identifier&oldid=1245316417},
  urldate = {2024-09-19},
  abstract = {An identifier is a name that identifies (that is, labels the identity of) either a unique object or a unique class of objects, where the "object" or class may be an idea, person, physical countable object (or class thereof), or physical noncountable substance (or class thereof). The abbreviation ID often refers to identity, identification (the process of identifying), or an identifier (that is, an instance of identification). An identifier may be a word, number, letter, symbol, or any combination of those. The words, numbers, letters, or symbols may follow an encoding system (wherein letters, digits, words, or symbols stand for [represent] ideas or longer names) or they may simply be arbitrary. When an identifier follows an encoding system, it is often referred to as a code or id code.  For instance the ISO/IEC 11179 metadata registry standard defines a code as system of valid symbols that substitute for longer values in contrast to identifiers without symbolic meaning. Identifiers that do not follow any encoding scheme are often said to be arbitrary Ids; they are arbitrarily assigned and have no greater meaning. (Sometimes identifiers are called "codes" even when they are actually arbitrary, whether because the speaker believes that they have deeper meaning or simply because they are speaking casually and imprecisely.) The unique identifier (UID) is an identifier that refers to only one instance---only one particular object in the universe. A part number is an identifier, but it is not a unique identifier---for that, a serial number is needed, to identify each instance of the part design. Thus the identifier "Model T" identifies the class (model) of automobiles that Ford's Model T comprises; whereas the unique identifier "Model T Serial Number 159,862" identifies one specific member of that class---that is, one particular Model T car, owned by one specific person. The concepts of name and identifier are denotatively equal, and the terms are thus denotatively synonymous; but they are not always connotatively synonymous, because code names and Id numbers are often connotatively distinguished from names in the sense of traditional natural language naming. For example, both "Jamie Zawinski" and "Netscape employee number 20" are identifiers for the same specific human being; but normal English-language connotation may consider "Jamie Zawinski" a "name" and not an "identifier", whereas it considers "Netscape employee number 20" an "identifier" but not a "name." This is an emic indistinction rather than an etic one.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1245316417}
}

@misc{InotifySharedDrives,
  title = {Inotify on Shared Drives Does Not Work {$\cdot$} {{Issue}} \#56 {$\cdot$} Docker/for-Win},
  url = {https://github.com/docker/for-win/issues/56},
  urldate = {2024-09-19}
}

@article{InputOutput2024,
  title = {Input/Output},
  year = {2024},
  month = aug,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Input/output&oldid=1238506785},
  urldate = {2024-09-19},
  abstract = {In computing, input/output (I/O, i/o, or informally io or IO) is the communication between an information processing system, such as a computer, and the outside world, such as another computer system, peripherals, or a human operator. Inputs are the signals or data received by the system and outputs are the signals or data sent from it. The term can also be used as part of an action; to "perform I/O" is to perform an input or output operation. I/O devices are the pieces of hardware used by a human (or other system) to communicate with a computer. For instance, a keyboard or computer mouse is an input device for a computer, while monitors and printers are output devices. Devices for communication between computers, such as modems and network cards, typically perform both input and output operations. Any interaction with the system by an interactor is an input and the reaction the system responds is called the output. The designation of a device as either input or output depends on perspective. Mice and keyboards take physical movements that the human user outputs and convert them into input signals that a computer can understand; the output from these devices is the computer's input. Similarly, printers and monitors take signals that computers output as input, and they convert these signals into a representation that human users can understand. From the human user's perspective, the process of reading or seeing these representations is receiving output; this type of interaction between computers and humans is studied in the field of human--computer interaction. A further complication is that a device traditionally considered an input device, e.g., card reader, keyboard, may accept control commands to, e.g., select stacker, display keyboard lights, while a device traditionally considered as an output device may provide status data (e.g., low toner, out of paper, paper jam). In computer architecture, the combination of the CPU and main memory, to which the CPU can read or write directly using individual instructions, is considered the brain of a computer. Any transfer of information to or from the CPU/memory combo, for example by reading data from a disk drive, is considered I/O. The CPU and its supporting circuitry may provide memory-mapped I/O that is used in low-level computer programming, such as in the implementation of device drivers, or may provide access to I/O channels. An I/O algorithm is one designed to exploit locality and perform efficiently when exchanging data with a secondary storage device, such as a disk drive.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1238506785}
}

@article{IntegratedDevelopmentEnvironment2024,
  title = {Integrated Development Environment},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Integrated_development_environment&oldid=1244675201},
  urldate = {2024-09-19},
  abstract = {An integrated development environment (IDE) is a software application that provides comprehensive facilities for software development. An IDE normally consists of at least a source-code editor, build automation tools, and a debugger. Some IDEs, such as IntelliJ IDEA, Eclipse and Lazarus contain the necessary compiler, interpreter or both; others, such as SharpDevelop and NetBeans, do not. The boundary between an IDE and other parts of the broader software development environment is not well-defined; sometimes a version control system or various tools to simplify the construction of a graphical user interface (GUI) are integrated. Many modern IDEs also have a class browser, an object browser, and a class hierarchy diagram for use in object-oriented software development.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1244675201}
}

@misc{IntroductionNixReferencea,
  title = {Introduction - {{Nix Reference Manual}}},
  url = {https://nix.dev/manual/nix/2.18/introduction},
  urldate = {2024-05-31}
}

@misc{LeadingContainerizationTechnologies,
  title = {Leading Containerization Technologies 2023},
  journal = {Statista},
  url = {https://www.statista.com/statistics/1256245/containerization-technologies-software-market-share/},
  urldate = {2024-07-07},
  abstract = {In 2023, Docker accounted for over 32 percent market share of the containerization technologies market.},
  langid = {english}
}

@misc{LinuxContainers,
  title = {Linux {{Containers}}},
  url = {https://linuxcontainers.org/},
  urldate = {2024-09-19},
  abstract = {The umbrella project behind Incus, LXC, LXCFS, Distrobuilder and more.},
  langid = {english}
}

@article{LinuxNamespaces2024,
  title = {Linux Namespaces},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Linux_namespaces&oldid=1243965513},
  urldate = {2024-09-15},
  abstract = {Namespaces are a feature of the Linux kernel that partition kernel resources such that one set of processes sees one set of resources, while another set of processes sees a different set of resources. The feature works by having the same namespace for a set of resources and processes, but those namespaces refer to distinct resources. Resources may exist in multiple namespaces. Examples of such resources are process IDs, host-names, user IDs, file names, some names associated with network access, and Inter-process communication. Namespaces are a required aspect of functioning containers in Linux. The term "namespace" is often used to denote a specific type of namespace (e.g., process ID) as well as for a particular space of names.  A Linux system begins with a single namespace of each type, used by all processes. Processes can create additional namespaces and can also join different namespaces.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1243965513}
}

@article{LispProgrammingLanguage2024,
  title = {Lisp (Programming Language)},
  year = {2024},
  month = jul,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Lisp_(programming_language)&oldid=1237652289},
  urldate = {2024-09-10},
  abstract = {Lisp (historically LISP, an abbreviation of "list processing") is a family of programming languages with a long history and a distinctive, fully parenthesized prefix notation. Originally specified in the late 1950s, it is the second-oldest high-level programming language still in common use, after Fortran. Lisp has changed since its early days, and many dialects have existed over its history. Today, the best-known general-purpose Lisp dialects are Common Lisp, Scheme, Racket, and Clojure. Lisp was originally created as a practical mathematical notation for computer programs, influenced by (though not originally derived from) the notation of Alonzo Church's lambda calculus. It quickly became a favored programming language for artificial intelligence (AI) research. As one of the earliest programming languages, Lisp pioneered many ideas in computer science, including tree data structures, automatic storage management, dynamic typing, conditionals, higher-order functions, recursion, the self-hosting compiler, and the read--eval--print loop. The name LISP derives from "LISt Processor". Linked lists are one of Lisp's major data structures, and Lisp source code is made of lists. Thus, Lisp programs can manipulate source code as a data structure, giving rise to the macro systems that allow programmers to create new syntax or new domain-specific languages embedded in Lisp. The interchangeability of code and data gives Lisp its instantly recognizable syntax. All program code is written as s-expressions, or parenthesized lists. A function call or syntactic form is written as a list with the function or operator's name first, and the arguments following; for instance, a function f that takes three arguments would be called as (f arg1 arg2 arg3).},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1237652289}
}

@inproceedings{malkaIncreasingTrustOpen2024,
  title = {Increasing Trust in the Open Source Supply Chain with Reproducible Builds and Functional Package Management},
  booktitle = {Proceedings of the 2024 {{IEEE}}/{{ACM}} 46th {{International Conference}} on {{Software Engineering}}: {{Companion Proceedings}}},
  author = {Malka, Julien},
  year = {2024},
  month = may,
  series = {{{ICSE-Companion}} '24},
  pages = {185--186},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3639478.3639806},
  url = {https://doi.org/10.1145/3639478.3639806},
  urldate = {2024-07-07},
  abstract = {Functional package managers (FPMs) and reproducible builds (R-B) are technologies and methodologies that are conceptually very different from the traditional software deployment model, and that have promising properties for software supply chain security. This thesis aims to evaluate the impact of FMPs and R-B on the security of the software supply chain and propose improvements to the FPM model to further improve trust in the open source supply chain.},
  isbn = {9798400705021}
}

@article{merkelDockerLightweightLinux2014,
  title = {Docker: Lightweight {{Linux}} Containers for Consistent Development and Deployment},
  shorttitle = {Docker},
  author = {Merkel, D.},
  year = {2014},
  month = mar,
  journal = {Linux Journal},
  url = {https://www.semanticscholar.org/paper/Docker%3A-lightweight-Linux-containers-for-consistent-Merkel/875d90d4f66b07f90687b27ab304e04a3f666fc2},
  urldate = {2024-09-10},
  abstract = {Docker promises the ability to package applications and their dependencies into lightweight containers that move easily between different distros, start up quickly and are isolated from each other.}
}

@inproceedings{muhammadTaxonomyPackageManagement2019,
  title = {Taxonomy of {{Package Management}} in {{Programming Languages}} and {{Operating Systems}}},
  booktitle = {Proceedings of the 10th {{Workshop}} on {{Programming Languages}} and {{Operating Systems}}},
  author = {Muhammad, Hisham and Real, Lucas C. Villa and Homer, Michael},
  year = {2019},
  month = oct,
  series = {{{PLOS}} '19},
  pages = {60--66},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3365137.3365402},
  url = {https://doi.org/10.1145/3365137.3365402},
  urldate = {2024-07-07},
  abstract = {Package management is instrumental for programming languages and operating systems, and yet it is neglected by both areas as an implementation detail. For this reason, it lacks the same kind of conceptual organization: we lack terminology to classify them or to reason about their design trade-offs. In this paper, we share our experience in both OS and language-specific package manager development, categorizing families of package managers and discussing their design implications beyond particular implementations. We also identify possibilities in the still largely unexplored area of package manager interoperability.},
  isbn = {978-1-4503-7017-2}
}

@misc{Networking0200,
  title = {Networking},
  year = {12:14:28 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/engine/network/},
  urldate = {2024-09-19},
  abstract = {Learn how networking works from the container's point of view},
  langid = {english}
}

@misc{nicoleNixParticleAccelerators2022,
  title = {Nix for Particle Accelerators, and the Adventure in Cross-Compilation},
  author = {Nicole, R{\'e}mi},
  year = {2022},
  publisher = {NixCon}
}

@misc{NixBasedFully,
  title = {Nix Based Fully Automated Workflows and Ecosystem to Guarantee Scientific Result Reproducibility across Software Environments and Systems {\textbar} {{Proceedings}} of the 3rd {{International Workshop}} on {{Software Engineering}} for {{High Performance Computing}} in {{Computational Science}} and {{Engineering}}},
  journal = {ACM Conferences},
  doi = {10.1145/2830168.2830172},
  url = {https://dl.acm.org/doi/10.1145/2830168.2830172},
  urldate = {2024-05-31},
  langid = {english}
}

@misc{NixBetterDocker2024,
  title = {Nix Is a Better {{Docker}} Image Builder than {{Docker}}'s Image Builder},
  year = {2024},
  month = may,
  url = {https://xeiaso.net//talks/2024/nix-docker-build/},
  urldate = {2024-05-28},
  abstract = {Xe Iaso's personal website.},
  langid = {english}
}

@misc{NixDevelopNix,
  title = {Nix Develop - {{Nix Reference Manual}}},
  url = {https://nix.dev/manual/nix/2.18/command-ref/new-cli/nix3-develop},
  urldate = {2024-09-19}
}

@misc{NixDockerBoth2023a,
  title = {Nix, {{Docker}} - or Both?},
  year = {2023},
  month = dec,
  journal = {Numtide},
  url = {https://numtide.com/blog/nix-docker-or-both/},
  urldate = {2024-05-28},
  abstract = {"It worked on my machine!" Most of us who've worked in IT for any length of time have heard this complaint. You develop your software, you test it exhaustively. It looks great. Then you deploy it into production and it crashes. And the blame game starts. Why does this happen?},
  langid = {english}
}

@misc{NixLanguageNixa,
  title = {Nix {{Language}} - {{Nix Reference Manual}}},
  url = {https://nix.dev/manual/nix/2.18/language/},
  urldate = {2024-05-31}
}

@misc{NixNixOSDeclarative,
  title = {Nix \& {{NixOS}} {\textbar} {{Declarative}} Builds and Deployments},
  url = {https://nixos.org/},
  urldate = {2024-06-20}
}

@misc{NixshellNixReference,
  title = {Nix-Shell - {{Nix Reference Manual}}},
  url = {https://nix.dev/manual/nix/2.18/command-ref/nix-shell},
  urldate = {2024-09-19}
}

@misc{NoItDefinitely,
  title = {No, It Definitely (but Unfortunately) Will Not. {{Nix}} Does Everything Docker Does ... {\textbar} {{Hacker News}}},
  url = {https://news.ycombinator.com/item?id=29387979},
  urldate = {2024-05-28}
}

@misc{OpenSourceProfessionals,
  title = {Open Source Professionals Most Important Tech 2022},
  journal = {Statista},
  url = {https://www.statista.com/statistics/639437/worldwide-open-source-survey-most-important-skills/},
  urldate = {2024-07-07},
  abstract = {The technologies of highest importance to global open source professionals in 2022 are cloud and containers, according to 71 percent of respondents.},
  langid = {english}
}

@article{OperatingSystem2024,
  title = {Operating System},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Operating_system&oldid=1245759229},
  urldate = {2024-09-19},
  abstract = {An operating system (OS) is system software that manages computer hardware and software resources, and provides common services for computer programs. Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, peripherals, and other resources. For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer -- from cellular phones and video game consoles to web servers and supercomputers. In the personal computer market, as of September 2023, Microsoft Windows holds a dominant market share of around 68\%. macOS by Apple Inc. is in second place (20\%), and the varieties of Linux, including ChromeOS, are collectively in third place (7\%). In the mobile sector (including smartphones and tablets), as of September 2023, Android's share is 68.92\%, followed by Apple's iOS and iPadOS with 30.42\%, and other operating systems with .66\%. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications. Security-focused operating systems also exist. Some operating systems have low system requirements (e.g. light-weight Linux distribution). Others may have higher system requirements. Some operating systems require installation or may come pre-installed with purchased computers (OEM-installation), whereas others may run directly from media (i.e. live CD) or flash memory (i.e. USB stick).},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1245759229}
}

@article{pahlContainerizationPaaSCloud2015,
  title = {Containerization and the {{PaaS Cloud}}},
  author = {Pahl, Claus},
  year = {2015},
  month = may,
  journal = {IEEE Cloud Computing},
  volume = {2},
  number = {3},
  pages = {24--31},
  issn = {2325-6095},
  doi = {10.1109/MCC.2015.51},
  url = {https://ieeexplore.ieee.org/document/7158965/?arnumber=7158965},
  urldate = {2024-07-07},
  abstract = {Containerization is widely discussed as a lightweight virtualization solution. Apart from exhibiting benefits over traditional virtual machines in the cloud, containers are especially relevant for platform-as-a-service (PaaS) clouds to manage and orchestrate applications through containers as an application packaging mechanism. This article discusses the requirements that arise from having to facilitate applications through distributed multicloud platforms.},
  keywords = {cloud,cloud computing,cluster,Computer architecture,container,Containerization,Docker,File systems,Kubernetes,Linux,multicloud,PaaS,Packaging,virtualization,Virtualization}
}

@misc{pardoItWorksMy2023,
  title = {``{{But}}{\dots} It Works on My Machine{\dots}''},
  author = {Pardo, J. A.},
  year = {2023},
  month = dec,
  journal = {Medium},
  url = {https://medium.com/@josetecangas/but-it-works-on-my-machine-cc8cca80660c},
  urldate = {2024-09-10},
  abstract = {The phrase ``It works on my machine'' has become a notorious, almost clich{\'e}d line that developers and testers often encounter. This seemingly{\dots}},
  langid = {english}
}

@misc{perkinsRevolutionizingMyDaily2022,
  title = {Revolutionizing My Daily Development with {{Nix}}},
  author = {Perkins, Luk},
  year = {2022},
  publisher = {NixCon}
}

@misc{PersistingContainerData0200,
  title = {Persisting Container Data},
  year = {12:14:28 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/get-started/docker-concepts/running-containers/persisting-container-data/},
  urldate = {2024-09-19},
  abstract = {This concept page will teach you the significance of data persistence in Docker},
  langid = {english}
}

@misc{Podman2024,
  title = {Podman},
  year = {2024},
  month = sep,
  url = {https://podman.io/},
  urldate = {2024-09-15},
  langid = {english}
}

@inproceedings{priedhorskyMinimizingPrivilegeBuilding2021,
  title = {Minimizing Privilege for Building {{HPC}} Containers},
  booktitle = {Proceedings of the {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Priedhorsky, Reid and Canon, R. Shane and Randles, Timothy and Younge, Andrew J.},
  year = {2021},
  month = nov,
  pages = {1--14},
  publisher = {ACM},
  address = {St. Louis Missouri},
  doi = {10.1145/3458817.3476187},
  url = {https://dl.acm.org/doi/10.1145/3458817.3476187},
  urldate = {2024-09-15},
  abstract = {HPC centers face increasing demand for software flexibility, and there is growing consensus that Linux containers are a promising solution. However, existing container build solutions require root privileges and cannot be used directly on HPC resources. This limitation is compounded as supercomputer diversity expands and HPC architectures become more dissimilar from commodity computing resources. Our analysis suggests this problem can best be solved with low-privilege containers. We detail relevant Linux kernel features, propose a new taxonomy of container privilege, and compare two open-source implementations: mostly-unprivileged rootless Podman and fully-unprivileged Charliecloud. We demonstrate that low-privilege container build on HPC resources works now and will continue to improve, giving normal users a better workflow to securely and correctly build containers. Minimizing privilege in this way can improve HPC user and developer productivity as well as reduce support workload for exascale applications.},
  copyright = {http://www.acm.org/publications/policies/copyright\_policy\#Background},
  isbn = {978-1-4503-8442-1},
  langid = {english}
}

@article{ProcessIdentifier2024,
  title = {Process Identifier},
  year = {2024},
  month = jun,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Process_identifier&oldid=1229884810},
  urldate = {2024-09-19},
  abstract = {In computing, the process identifier (a.k.a. process ID or PID) is a number used by most operating system kernels---such as those of Unix, macOS and Windows---to uniquely identify an active process. This number may be used as a parameter in various function calls, allowing processes to be manipulated, such as adjusting the process's priority or killing it altogether.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1229884810}
}

@article{queirozContainerbasedVirtualizationRealtime2024,
  title = {Container-Based {{Virtualization}} for {{Real-time Industrial Systems}}---{{A Systematic Review}}},
  author = {Queiroz, Rui and Cruz, Tiago and Mendes, J{\'e}r{\^o}me and Sousa, Pedro and Sim{\~o}es, Paulo},
  year = {2024},
  month = mar,
  journal = {ACM Computing Surveys},
  volume = {56},
  number = {3},
  pages = {1--38},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3617591},
  url = {https://dl.acm.org/doi/10.1145/3617591},
  urldate = {2024-09-15},
  abstract = {Industrial Automation and Control systems have matured into a stable infrastructure model that has been kept fundamentally unchanged, using discrete embedded systems (such as Programmable Logic Controllers) to implement the first line of sensorization, actuation, and process control and stations and servers providing monitoring, supervision, logging/database and data-sharing capabilities, among others. More recently, with the emergence of the Industry 4.0 paradigm and the need for more flexibility, there has been a steady trend towards virtualizing some of the automation station/server components, first by using virtual machines and, more recently, by using container technology. This trend is pushing for better support for real-time requirements on enabling virtualization technologies such as virtual machines and containers.             This article provides a systematic review on the use of container virtualization in real-time environments such as cyber-physical systems, assessing how existing and emerging technologies can fulfill the associated requirements. Starting by reviewing fundamental concepts related to container technology and real-time requirements, it goes on to present the methodology and results of a systematic study of 37 selected papers covering aspects related to the enforcement of real-time constrains within container hosts and the expected task latency on such environments, as well as an overview of container platforms and orchestration mechanisms for RT systems.},
  langid = {english}
}

@article{rahmanWorksMeCannot2022,
  title = {Works for {{Me}}! {{Cannot Reproduce}} -- {{A Large Scale Empirical Study}} of {{Non-reproducible Bugs}}},
  author = {Rahman, Mohammad M. and Khomh, Foutse and Castelluccio, Marco},
  year = {2022},
  month = may,
  journal = {Empirical Software Engineering},
  volume = {27},
  number = {5},
  pages = {111},
  issn = {1573-7616},
  doi = {10.1007/s10664-022-10153-2},
  url = {https://doi.org/10.1007/s10664-022-10153-2},
  urldate = {2024-09-10},
  abstract = {Software developers attempt to reproduce software bugs to understand their erroneous behaviours and to fix them. Unfortunately, they often fail to reproduce (or fix) them, which leads to faulty, unreliable software systems. However, to date, only a little research has been done to better understand what makes the software bugs non-reproducible. In this article, we conduct a multimodal study to better understand the non-reproducibility of software bugs. First, we perform an empirical study using 576 non-reproducible bug reports from two popular software systems (Firefox, Eclipse) and identify 11 key factors that might lead a reported bug to non-reproducibility. Second, we conduct a user study involving 13 professional developers where we investigate how the developers cope with non-reproducible bugs. We found that they either close these bugs or solicit for further information, which involves long deliberations and counter-productive manual searches. Third, we offer several actionable insights on how to avoid non-reproducibility (e.g., false-positive bug report detector) and improve reproducibility of the reported bugs (e.g., sandbox for bug reproduction) by combining our analyses from multiple studies (e.g., empirical study, developer study). Fourth, we explain the differences between reproducible and non-reproducible bug reports by systematically interpreting multiple machine learning models that classify these reports with high accuracy. We found that links to existing bug reports might help improve the reproducibility of a reported bug. Finally, we detect the connected bug reports to a non-reproducible bug automatically and further demonstrate how 93 bugs connected to 71 non-reproducible bugs from our dataset can offer complementary information (e.g., attachments, screenshots, program flows).},
  langid = {english},
  keywords = {Artificial Intelligence,Bug report classification,Bug reproduction,Developer feedback,Empirical study,Grounded theory,Key factors,Model interpretation,Non-reproducibility,Reproducibility challenges}
}

@misc{RedHatWe,
  title = {Red {{Hat}} - {{We}} Make Open Source Technologies for the Enterprise},
  url = {https://www.redhat.com/en},
  urldate = {2024-09-15},
  abstract = {Red Hat is the world's leading provider of enterprise open source solutions, including high-performing Linux, cloud, container, and Kubernetes technologies.},
  langid = {english}
}

@misc{replitReplitWillNix2021,
  title = {Replit --- {{Will Nix Overtake Docker}}?},
  author = {Replit},
  year = {2021},
  month = nov,
  journal = {Replit Blog},
  url = {https://blog.replit.com/nix-vs-docker},
  urldate = {2024-05-28},
  abstract = {In many discussions about Nix, the comparison of Nix and Docker comes up frequently. This question could be dismissed by saying that Nix and Docker are different tools that solve different problems. One is a toolkit for building and deploying containers and the other is a package and configuration manager. However, these tools do have some overlap: they can both be used to create reproducible environments. A reproducible environment is one that can be recreated from scratch in an identical way (ideally bit-for-bit). Practically, this means having the same tools, versions, and configuration between the environments. Reproducible environments are useful to ensure all developers on a project have the exact same set of tools. Additionally, you can develop in an environment that is similar to the production environment -- leading to less surprises when deploying. Both tools can solve the age-old problem of "it works on my machine". While both tools aim to solve this problem, they take different approaches.}
}

@misc{RustProgrammingLanguage,
  title = {Rust {{Programming Language}}},
  url = {https://www.rust-lang.org/},
  urldate = {2024-09-19},
  abstract = {A language empowering everyone to build reliable and efficient software.},
  langid = {american}
}

@misc{SDKSoftwareDevelopment2023,
  title = {{{SDK}} ({{Software Development Kit}}) - {{MDN Web Docs Glossary}}: {{Definitions}} of {{Web-related}} Terms {\textbar} {{MDN}}},
  shorttitle = {{{SDK}} ({{Software Development Kit}}) - {{MDN Web Docs Glossary}}},
  year = {2023},
  month = jun,
  url = {https://developer.mozilla.org/en-US/docs/Glossary/SDK},
  urldate = {2024-08-27},
  abstract = {An SDK (Software Development Kit) is an integrated collection of tools that a developer can use to create software for a specific framework, operating system, or other platform. An SDK can include:},
  langid = {american}
}

@article{silvaContainersVirtualizationOverview2018,
  title = {Containers for {{Virtualization}}: {{An Overview}}},
  shorttitle = {Containers for {{Virtualization}}},
  author = {Silva, Vitor and Kirikova, Marite and Alksnis, Gundars},
  year = {2018},
  month = may,
  journal = {Applied Computer Systems},
  volume = {23},
  pages = {21--27},
  doi = {10.2478/acss-2018-0003},
  abstract = {Virtualization has enabled the commoditization of cloud computing, as the hardware resources have become available to run different environments and share computing resources amongst different enterprises. Two technology types are commonly used in virtualization of hardware, namely, hypervisor and container. The present paper concerns only container technologies. A comprehensive overview of the container technologies for virtualization and the dynamics of their popularity have not been available yet. Without such an overview, the informed fast choice of technologies is hindered. To fill this knowledge gap, a systemic literature review was conducted to reveal the most popular container technologies and the trends in their research.}
}

@inproceedings{simecIsolatedEnvironmentTools2018,
  title = {Isolated {{Environment Tools}} for {{Software Development}}},
  booktitle = {2018 {{International Conference}} on {{Applied Mathematics}} \& {{Computer Science}} ({{ICAMCS}})},
  author = {{\v S}imec, Alen and Dr{\v z}ani{\'c}, Bruno and Lozi{\'c}, Davor},
  year = {2018},
  month = apr,
  pages = {48--484},
  doi = {10.1109/ICAMCS46079.2018.00016},
  url = {https://ieeexplore.ieee.org/document/8955312/?arnumber=8955312},
  urldate = {2024-07-07},
  abstract = {Docker and Vagrant are virtualization containers. Both worlds have their own quirks but each one serves their purpose well. Vagrant, the older brother, uses virtual machines to create isolated environments for software development. On the other side, Docker uses another technique called Containers for isolation and in that term uses local system files and resources. Before those tools, there were so many problems with porting applications, setting them up on other development machines or servers. The problem was that all machines had different setups, some had different versions of required files or they didn't have required extensions. Modern distributed applications development often faces two problems, first problem is inconsistency of development environments because of multiple versions of operating systems and packages and the second one is services and discrepancies between development and test/deployment environments. Virtualization technology, such as virtual machines (VMs) and containers that can handle these problems effectively, but they are often difficult to use in real-world development processes due to the lack of appropriate tools for developers. Modern distributed applications, especially web applications, are typically built using a set of loosely coupled services, with rapid development and deployment cycles. These services may run in multiple virtual machines and are ephemeral according to clients demands. This paper presents both tools, compares them and shows which one of them is the best for which specific use. The purpose of this paper is to show when and why to use which tool and to show advantages and disadvantages of each one.},
  keywords = {comparison,development,Docker,Isolated enviroment,software,Vagrant,virtualization}
}

@article{SoftwarePortability2024,
  title = {Software Portability},
  year = {2024},
  month = jun,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Software_portability&oldid=1229915379},
  urldate = {2024-09-15},
  abstract = {Software portability is a design objective for source code to be easily made to run on different platforms. An aid to portability is the generalized abstraction between the application logic and system interfaces. When software with the same functionality is produced for several computing platforms, portability is the key issue for development cost reduction.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1229915379}
}

@article{SystemImage2024,
  title = {System Image},
  year = {2024},
  month = apr,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=System_image&oldid=1220330204#Process_images},
  urldate = {2024-09-15},
  abstract = {In computing, a system image is a serialized copy of the entire state of a computer system stored in some non-volatile form, such as a file.  If a system has all its state written to a disk (i.e. on a disk image), then a system image can be produced by copying the disk to a file elsewhere, often with disk cloning applications. On many systems a complete system image cannot be created by a disk cloning program running within that system because information can be held outside of disks and volatile memory, for example in non-volatile memory like boot ROMs. A system is said to be capable of using system images if it can be shut down and later restored to exactly the same state. In such cases, system images can be used for backup. Hibernation is an example that uses an image of the entire machine's RAM.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1220330204}
}

@misc{TailwindCSSRapidly2020,
  title = {Tailwind {{CSS}} - {{Rapidly}} Build Modern Websites without Ever Leaving Your {{HTML}}.},
  year = {2020},
  month = nov,
  url = {https://tailwindcss.com/},
  urldate = {2024-09-19},
  abstract = {Tailwind CSS is a utility-first CSS framework for rapidly building modern websites without ever leaving your HTML.},
  langid = {english}
}

@misc{ThereMuchDifference2018,
  title = {Is There Much Difference between Using Nix-Shell and Docker for Local Development?},
  year = {2018},
  month = aug,
  journal = {NixOS Discourse},
  url = {https://discourse.nixos.org/t/is-there-much-difference-between-using-nix-shell-and-docker-for-local-development/807},
  urldate = {2024-05-31},
  abstract = {I'm still quite new to the Nix scene, but I feel like I've finally got the language down and am managing all of my personal projects and machines with Nix to great success. My company uses PHP and we have TONS of small deployed projects, some of which are still on PHP 5.5.9 servers!  I used to use brew to link between different PHP versions to match the deployment environment and, especially since brew's support for PHP is quickly declining, it's been a life-saver to have a shell.nix for each of...},
  chapter = {Help},
  langid = {english}
}

@misc{UnderstandingImageLayers0200,
  title = {Understanding the Image Layers},
  year = {13:57:13 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/get-started/docker-concepts/building-images/understanding-image-layers/},
  urldate = {2024-09-19},
  abstract = {This concept page will teach you about the layers of container image.},
  langid = {english}
}

@inproceedings{vaillancourtSelfScalingClustersReproducible2020,
  title = {Self-{{Scaling Clusters}} and {{Reproducible Containers}} to {{Enable Scientific Computing}}},
  booktitle = {2020 {{IEEE High Performance Extreme Computing Conference}} ({{HPEC}})},
  author = {Vaillancourt, Peter Z. and Coulter, J. Eric and Knepper, Richard and Barker, Brandon},
  year = {2020},
  month = sep,
  pages = {1--8},
  issn = {2643-1971},
  doi = {10.1109/HPEC43674.2020.9286208},
  url = {https://ieeexplore.ieee.org/document/9286208/?arnumber=9286208},
  urldate = {2024-07-07},
  abstract = {Container technologies such as Docker have become a crucial component of many software industry practices especially those pertaining to reproducibility and portability. The containerization philosophy has influenced the scientific computing community, which has begun to adopt - and even develop - container technologies (such as Singularity). Leveraging containers for scientific software often poses challenges distinct from those encountered in industry, and requires different methodologies. This is especially true for HPC. With an increasing number of options for HPC in the cloud (including NSF-funded cloud projects), there is strong motivation to seek solutions that provide flexibility to develop and deploy scientific software on a variety of computational infrastructures in a portable and reproducible way. The Cyberinfrastructure Resource Integration team in the XSEDE project has developed a simple tool which provides HPC infrastructure in the cloud that scales with user demand. We now present one possible solution which uses the Nix package manager in an MPI-capable Docker container that is converted to Singularity. It provides consistent installations, dependencies, and environments in each image that are reproducible and portable across scientific computing infrastructures. We demonstrate the utility of these containers with cluster benchmark runs in a self-scaling virtual cluster using the Slurm scheduler deployed in the Jetstream and Aristotle Red Cloud OpenStack clouds. We conclude that this technique is useful as a template for scientific software application containers to be used in the XSEDE compute environment, other Singularity HPC environments, and cloud computing environments.},
  keywords = {Cloud,Cloud computing,Cluster,Containers,Cyberinfrastructure,Docker,HPC,Industries,Libraries,MPI,Scientific computing,Scientific Computing,Singularity,Slurm,Software,Veins}
}

@inproceedings{vanderburgAutomatingSystemTests2010,
  title = {Automating {{System Tests Using Declarative Virtual Machines}}},
  booktitle = {2010 {{IEEE}} 21st {{International Symposium}} on {{Software Reliability Engineering}}},
  author = {{van der Burg}, Sander and Dolstra, Eelco},
  year = {2010},
  month = nov,
  pages = {181--190},
  issn = {2332-6549},
  doi = {10.1109/ISSRE.2010.34},
  url = {https://ieeexplore.ieee.org/document/5635141/?arnumber=5635141},
  urldate = {2024-07-07},
  abstract = {Automated regression test suites are an essential software engineering practice: they provide developers with rapid feedback on the impact of changes to a system's source code. The inclusion of a test case in an automated test suite requires that the system's build process can automatically provide all the environmental dependencies of the test. These are external elements necessary for a test to succeed, such as shared libraries, running programs, and so on. For some tests (e.g., a compiler's), these requirements are simple to meet. However, many kinds of tests, especially at the integration or system level, have complex dependencies that are hard to provide automatically, such as running database servers, administrative privileges, services on external machines or specific network topologies. As such dependencies make tests difficult to script, they are often only performed manually, if at all. This particularly affects testing of distributed systems and system-level software. This paper shows how we can automatically instantiate the complex environments necessary for tests by creating (networks of) virtual machines on the fly from declarative specifications. Building on NixOS, a Linux distribution with a declarative configuration model, these specifications concisely model the required environmental dependencies. We also describe techniques that allow efficient instantiation of VMs. As a result, complex system tests become as easy to specify and execute as unit tests. We evaluate our approach using a number of representative problems, including automated regression testing of a Linux distribution.},
  keywords = {Buildings,Kernel,Linux,Network topology,Servers,Virtual machining}
}

@misc{WhatImage0200,
  title = {What Is an Image?},
  year = {12:14:28 +0200 +0200},
  journal = {Docker Documentation},
  url = {https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-an-image/},
  urldate = {2024-09-19},
  abstract = {What is an image},
  langid = {english}
}

@misc{WhyDidDocker,
  title = {Why Did {{Docker}} Become so Popular When a More Robust and Mathematically Immutable Method via {{NixOS}}' {{Nix}} Packaging Is out There?},
  journal = {Quora},
  url = {https://www.quora.com/Why-did-Docker-become-so-popular-when-a-more-robust-and-mathematically-immutable-method-via-NixOS-Nix-packaging-is-out-there},
  urldate = {2024-05-28},
  abstract = {Answer (1 of 3): Immutability of images is not the only component of Docker. There are many immutable distribution mechanisms, going back far older than Linux. It is not a new concept. Nix brings a number of features to Linux systems, but immutability is not really a signal feature. You will not...},
  langid = {english}
}

@article{WindowsSubsystemLinux2024,
  title = {Windows {{Subsystem}} for {{Linux}}},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Windows_Subsystem_for_Linux&oldid=1245669237},
  urldate = {2024-09-19},
  abstract = {Windows Subsystem for Linux (WSL) is a feature of Microsoft Windows that allows developers to run a Linux environment without the need for a separate virtual machine or dual booting. There are two versions of WSL: WSL 1 and WSL 2.  WSL is not available to all Windows 10 users by default. It can be installed either by joining the Windows Insider program or manually via Microsoft Store or Winget. WSL 1 was first released on August 2, 2016, and acted as a compatibility layer for running Linux binary executables (in ELF format) by implementing Linux system calls in the Windows kernel. It is available on Windows 10, Windows 10 LTSB/LTSC, Windows 11, Windows Server 2016, Windows Server 2019 and Windows Server 2022.  In May 2019, WSL 2 was announced, introducing important changes such as a real Linux kernel, through a subset of Hyper-V features. WSL 2 differs from WSL 1 in that WSL 2 runs inside a managed virtual machine that implements the full Linux kernel. As a result, WSL 2 is compatible with more Linux binaries than WSL 1, as not all system calls were implemented in WSL 1. Since June 2019, WSL 2 is available to Windows 10 customers through the Windows Insider program, including the Home edition.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1245669237}
}

@misc{yagisNixDocker2021,
  title = {Nix or {{Docker}}?},
  author = {Ya{\u g}{\i}{\c s}, Mehmet Yavuz},
  year = {2021},
  month = jan,
  journal = {Medium},
  url = {https://mehmetyavuzyagis.medium.com/nix-or-docker-db1dc667f404},
  urldate = {2024-05-28},
  abstract = {Two Different Approaches, Two Different Solutions, One Problem At Hand.},
  langid = {english}
}

@misc{YouAreMost2018,
  title = {You {{Are Most Likely Misusing Docker}}},
  year = {2018},
  month = may,
  url = {https://www.mpscholten.de/docker/2016/01/27/you-are-most-likely-misusing-docker.html},
  urldate = {2024-05-28}
}

@inproceedings{yuBugsPodsUnderstanding2024,
  title = {Bugs in {{Pods}}: {{Understanding Bugs}} in {{Container Runtime Systems}}},
  shorttitle = {Bugs in {{Pods}}},
  booktitle = {Proceedings of the 33rd {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  author = {Yu, Jiongchi and Xie, Xiaofei and Zhang, Cen and Chen, Sen and Li, Yuekang and Shen, Wenbo},
  year = {2024},
  month = sep,
  pages = {1364--1376},
  publisher = {ACM},
  address = {Vienna Austria},
  doi = {10.1145/3650212.3680366},
  url = {https://dl.acm.org/doi/10.1145/3650212.3680366},
  urldate = {2024-09-15},
  abstract = {Container Runtime Systems (CRSs), which form the foundational infrastructure of container clouds, are critically important due to their impact on the quality of container cloud implementations. However, a comprehensive understanding of the quality issues present in CRS implementations remains lacking. To bridge this gap, we conduct the first comprehensive empirical study of CRS bugs. Specifically, we gather 429 bugs from 8,271 commits across dominant CRS projects, including runc, gvisor, containerd, and cri-o. Through manual analysis, we develop taxonomies of CRS bug symptoms and root causes, comprising 16 and 13 categories, respectively. Furthermore, we evaluate the capability of popular testing approaches, including unit testing, integration testing, and fuzz testing in detecting these bugs. The results show that 78.79\% of the bugs cannot be detected due to the lack of test drivers, oracles, and effective test cases. Based on the findings of our study, we present implications and future research directions for various stakeholders in the domain of CRSs. We hope that our work can lay the groundwork for future research on CRS bug detection.},
  isbn = {9798400706127},
  langid = {english}
}

@inproceedings{zengResearchDockerContainer2023,
  title = {Research on {{Docker Container Network Isolation}} and {{Security Management}} for {{Multi-Tenant Environments}}},
  booktitle = {Proceedings of the 2023 {{International Conference}} on {{Communication Network}} and {{Machine Learning}}},
  author = {Zeng, Weijie and Fan, Rui and Wang, Zhi and Xiao, Yu and Huang, Rui and Liu, Mouhai},
  year = {2023},
  month = oct,
  pages = {179--185},
  publisher = {ACM},
  address = {Zhengzhou China},
  doi = {10.1145/3640912.3640948},
  url = {https://dl.acm.org/doi/10.1145/3640912.3640948},
  urldate = {2024-09-15},
  abstract = {This paper establishes a portal middleware platform for multi-tenant environments that can support higher tenant density and reduce the cost of software management and maintenance. It analyzes the advantages of Docker containers compared with traditional virtual machines in running applications, and introduces the whole architecture of Docker containers. By virtue of the multi-level security container isolation mechanism to achieve effective isolation and management of resources, it can effectively protect the security and integrity of the shared data between containers, and establish a configuration file-based shared data volume security isolation scheme CMAC. realize the fine-grained access control and isolation of the shared data volume. Experimental results show that the defense posture assessment accuracy of the multilevel security container isolation method proposed in this paper reaches more than 92\%, and the efficiency of network security defense posture assessment, is always above 87\%. It shows that the proposed method can isolate the script virus in a timely and effective manner.},
  isbn = {9798400716683},
  langid = {english}
}

@article{zhaoEndtoendHighperformanceDeduplication2024,
  title = {An {{End-to-end High-performance Deduplication Scheme}} for {{Docker Registries}} and {{Docker Container Storage Systems}}},
  author = {Zhao, Nannan and Lin, Muhui and Albahar, Hadeel and Paul, Arnab K. and Huan, Zhijie and Abraham, Subil and Chen, Keren and Tarasov, Vasily and Skourtis, Dimitrios and Anwar, Ali and Butt, Ali},
  year = {2024},
  month = jun,
  journal = {ACM Trans. Storage},
  volume = {20},
  number = {3},
  pages = {18:1--18:35},
  issn = {1553-3077},
  doi = {10.1145/3643819},
  url = {https://doi.org/10.1145/3643819},
  urldate = {2024-08-06},
  abstract = {The wide adoption of Docker containers for supporting agile and elastic enterprise applications has led to a broad proliferation of container images. The associated storage performance and capacity requirements place a high pressure on the infrastructure of container registries that store and distribute images and container storage systems on the Docker client side that manage image layers and store ephemeral data generated at container runtime. The storage demand is worsened by the large amount of duplicate data in images. Moreover, container storage systems that use Copy-on-Write (CoW) file systems as storage drivers exacerbate the redundancy. Exploiting the high file redundancy in real-world images is a promising approach to drastically reduce the growing storage requirements of container registries and improve the space efficiency of container storage systems. However, existing deduplication techniques significantly degrade the performance of both registries and container storage systems because of data reconstruction overhead as well as the deduplication cost.We propose DupHunter, an end-to-end deduplication scheme that deduplicates layers for both Docker registries and container storage systems while maintaining a high image distribution speed and container I/O performance. DupHunter is divided into three tiers: registry tier, middle tier, and client tier. Specifically, we first build a high-performance deduplication engine at the registry tier that not only natively deduplicates layers for space savings but also reduces layer restore overhead. Then, we use deduplication offloading at the middle tier to eliminate the redundant files from the client tier and avoid bringing deduplication overhead to the clients. To further reduce the data duplicates caused by CoWs and improve the container I/O performance, we utilize a container-aware storage system at the client tier that reserves space for each container and arranges the placement of files and their modifications on the disk to preserve locality. Under real workloads, DupHunter reduces storage space by up to 6.9{\texttimes} and reduces the GET layer latency up to 2.8{\texttimes} compared to the state-of-the-art. Moreover, DupHunter can improve the container I/O performance by up to 93\% for reads and 64\% for writes.}
}
